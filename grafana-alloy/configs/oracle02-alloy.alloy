// =============================================================================
// Grafana Alloy Configuration - Oracle02 (Application Server)
// =============================================================================
// Purpose: Collect logs and metrics, send to centralized Oracle01
// Sends: Logs → Loki-Oracle01, Metrics → Mimir-Oracle01
// Server: oracle02 (10.0.206.20) - 12GB RAM - Web Hosting Server
// =============================================================================

logging {
  level  = "info"
  format = "logfmt"
}

// =============================================================================
// REMOTE ENDPOINTS (Oracle01 - Monitoring Hub)
// =============================================================================

loki.write "loki_central" {
  endpoint {
    url = "http://10.0.206.10:3100/loki/api/v1/push"
  }
}

prometheus.remote_write "mimir_central" {
  endpoint {
    url = "http://10.0.206.10:9009/api/v1/push"
  }
}

// =============================================================================
// LOG COLLECTION - ORACLE02
// =============================================================================

// -----------------------------------------------------------------------------
// Syslog Collection
// -----------------------------------------------------------------------------
local.file_match "syslog" {
  path_targets = [
    {
      __path__ = "/var/log/syslog",
      job      = "syslog",
      host     = "oracle02",
    },
  ]
}

loki.source.file "syslog" {
  targets    = local.file_match.syslog.targets
  forward_to = [loki.process.syslog.receiver]
}

loki.process "syslog" {
  stage.static_labels {
    values = {
      job  = "syslog",
      host = "oracle02",
    }
  }
  forward_to = [loki.write.loki_central.receiver]
}

// -----------------------------------------------------------------------------
// Nginx Logs - REDUCED CARDINALITY!
// -----------------------------------------------------------------------------
// This is the KEY FIX for "maximum active stream limit exceeded" errors!
// Before: Created one stream PER LOG FILE (10+ websites = 10+ streams)
// After: Creates streams by job/host/website only (~10-20 streams total)

local.file_match "nginx_access" {
  path_targets = [
    {
      __path__ = "/var/www/html/*/logs/access.log",
      job      = "nginx_access",
      host     = "oracle02",
    },
  ]
}

loki.source.file "nginx_access" {
  targets    = local.file_match.nginx_access.targets
  forward_to = [loki.process.nginx_access.receiver]
}

loki.process "nginx_access" {
  // Parse nginx combined log format
  stage.regex {
    expression = "^(?P<remote_addr>[\\w\\.\\:]+) - (?P<remote_user>[^ ]*) \\[(?P<time_local>[^\\]]*)\\] \"(?P<method>\\S+) (?P<request_uri>\\S+) (?P<http_version>\\S+)\" (?P<status>\\d+) (?P<body_bytes_sent>\\d+) \"(?P<http_referer>[^\"]*)\" \"(?P<http_user_agent>[^\"]*)\""
  }

  // Extract website name from file path
  stage.regex {
    source     = "filename"
    expression = "/var/www/html/(?P<website>[^/]+)/logs/"
  }

  // GeoIP enrichment for visitor IP
  // This adds geoip_* fields to the extracted map
  stage.geoip {
    db      = "/geoip/GeoLite2-City.mmdb"
    source  = "remote_addr"
    db_type = "city"
  }

  // Pack extracted fields (including GeoIP data) into JSON format in log content
  // This makes ALL fields queryable with | json parser in LogQL
  stage.pack {
    labels = [
      "remote_addr", "remote_user", "method", "request_uri",  // Request fields
      "status", "body_bytes_sent", "http_referer", "http_user_agent",  // Response fields
      "geoip_country_name", "geoip_city_name",  // GeoIP fields
      "geoip_location_latitude", "geoip_location_longitude",
      "geoip_country_code", "geoip_continent_name",
    ]
    ingest_timestamp = false  // Keep original timestamp from nginx
  }

  // CRITICAL: Only use LOW-CARDINALITY labels!
  stage.labels {
    values = {
      website = "website",  // Only ~10 unique values
    }
  }

  stage.static_labels {
    values = {
      job  = "nginx_access",
      host = "oracle02",
    }
  }

  // Now all fields are in JSON log content (not labels)
  // Query them with LogQL:
  // {job="nginx_access"} | json | remote_addr="1.2.3.4" | status="404"
  // {job="nginx_access"} | json | geoip_country_name="United States"
  // {job="nginx_access"} | json | method="POST" | request_uri=~"/api/.*"

  forward_to = [loki.write.loki_central.receiver]
}

// -----------------------------------------------------------------------------
// Nginx Error Logs
// -----------------------------------------------------------------------------
local.file_match "nginx_error" {
  path_targets = [
    {
      __path__ = "/var/www/html/*/logs/error.log",
      job      = "nginx_error",
      host     = "oracle02",
    },
  ]
}

loki.source.file "nginx_error" {
  targets    = local.file_match.nginx_error.targets
  forward_to = [loki.process.nginx_error.receiver]
}

loki.process "nginx_error" {
  // Extract website name
  stage.regex {
    source     = "filename"
    expression = "/var/www/html/(?P<website>[^/]+)/logs/"
  }

  stage.labels {
    values = {
      website = "website",
    }
  }

  stage.static_labels {
    values = {
      job  = "nginx_error",
      host = "oracle02",
    }
  }

  forward_to = [loki.write.loki_central.receiver]
}

// -----------------------------------------------------------------------------
// Suricata IDS Logs - FIXED CARDINALITY!
// -----------------------------------------------------------------------------
// This was creating 10,000+ streams due to high-cardinality labels!
// Before: src_ip, dest_port, geoip_city, geoip_lat/long, signature as labels
// After: Only event_type and proto as labels (~20-50 streams total)

local.file_match "suricata" {
  path_targets = [
    {
      __path__ = "/var/log/suricata/eve.json",
      job      = "suricata",
      host     = "oracle02",
    },
  ]
}

loki.source.file "suricata" {
  targets    = local.file_match.suricata.targets
  forward_to = [loki.process.suricata.receiver]
}

loki.process "suricata" {
  // Parse JSON log format (Suricata eve.json logs are already in JSON)
  // Extract comprehensive fields for better visibility and analysis
  stage.json {
    expressions = {
      // Core event fields
      event_type = "event_type",
      timestamp  = "timestamp",
      flow_id    = "flow_id",
      in_iface   = "in_iface",

      // Network layer
      proto      = "proto",
      src_ip     = "src_ip",
      dest_ip    = "dest_ip",
      src_port   = "src_port",
      dest_port  = "dest_port",

      // Application layer detection
      app_proto  = "app_proto",  // Detected protocol (HTTP, TLS, DNS, SSH, etc.)

      // Alert fields (when event_type="alert")
      signature    = "alert.signature",
      signature_id = "alert.signature_id",
      category     = "alert.category",
      severity     = "alert.severity",
      action       = "alert.action",      // allow/block/drop

      // Flow metadata (when event_type="flow")
      flow_state   = "flow.state",        // established, closed, new, etc.
      flow_reason  = "flow.reason",       // timeout, shutdown, etc.
      flow_age     = "flow.age",          // duration of flow in seconds
      bytes_toserver = "flow.bytes_toserver",
      bytes_toclient = "flow.bytes_toclient",
      pkts_toserver  = "flow.pkts_toserver",
      pkts_toclient  = "flow.pkts_toclient",
    }
  }

  // GeoIP enrichment for source IP
  // This adds geoip_* fields to the extracted map
  stage.geoip {
    db      = "/geoip/GeoLite2-City.mmdb"
    source  = "src_ip"
    db_type = "city"
  }

  // Pack extracted fields (including GeoIP data) into JSON format in log content
  // This embeds all Suricata event data + GeoIP enrichment for querying
  stage.pack {
    labels = [
      // Core event metadata
      "timestamp", "flow_id", "in_iface", "app_proto",

      // Network fields
      "src_ip", "dest_ip", "src_port", "dest_port",

      // Alert fields (for event_type="alert")
      "signature", "signature_id", "category", "severity", "action",

      // Flow metadata (for event_type="flow")
      "flow_state", "flow_reason", "flow_age",
      "bytes_toserver", "bytes_toclient", "pkts_toserver", "pkts_toclient",

      // GeoIP enrichment
      "geoip_country_name", "geoip_city_name",
      "geoip_location_latitude", "geoip_location_longitude",
      "geoip_country_code", "geoip_continent_name",
    ]
    ingest_timestamp = false  // Keep original timestamp from Suricata
  }

  // CRITICAL: Only use LOW-CARDINALITY labels!
  stage.labels {
    values = {
      event_type = "event_type",  // ~10 unique values (flow, alert, tls, dns, http)
      proto      = "proto",       // ~5 unique values (TCP, UDP, ICMP, etc.)
    }
  }

  stage.static_labels {
    values = {
      job  = "suricata",
      host = "oracle02",
    }
  }

  // Now all fields are in JSON log content (not labels)
  // Query examples with LogQL:
  //
  // Alert queries:
  // {job="suricata", event_type="alert"} | json | src_ip="45.225.192.88"
  // {job="suricata", event_type="alert"} | json | signature=~".*SQL.*"
  // {job="suricata", event_type="alert"} | json | severity="1" | geoip_country_name!=""
  // {job="suricata", event_type="alert"} | json | category="Attempted Administrator Privilege Gain"
  //
  // Flow analysis:
  // {job="suricata", event_type="flow"} | json | app_proto="http" | flow_state="established"
  // {job="suricata", event_type="flow"} | json | bytes_toserver > 1000000  // Large uploads
  // {job="suricata", event_type="flow"} | json | flow_reason="timeout" | flow_age > 300
  //
  // GeoIP queries:
  // {job="suricata"} | json | geoip_country_name="China"
  // {job="suricata"} | json | geoip_country_name!="" | line_format "{{.src_ip}} from {{.geoip_city_name}}, {{.geoip_country_name}}"

  forward_to = [loki.write.loki_central.receiver]
}

// =============================================================================
// METRICS COLLECTION - ORACLE02
// =============================================================================
// Currently, Oracle01's Alloy scrapes Oracle02's metrics remotely.
// If you want local collection + forwarding, uncomment below:

/*
prometheus.scrape "node_exporter" {
  targets = [
    {"__address__" = "10.0.206.20:9100", "instance" = "oracle02"},
  ]
  forward_to = [prometheus.remote_write.mimir_central.receiver]
}

prometheus.scrape "cadvisor" {
  targets = [
    {"__address__" = "10.0.206.20:9200", "instance" = "oracle02"},
  ]
  forward_to = [prometheus.remote_write.mimir_central.receiver]
}
*/
